---
title: "Clustering Lab"
author: "Brian Wright"
date: "9/20/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(plotly)
library(htmltools)
library(devtools)
library(caret)
library(NbClust)
library(readr)
house_votes_Rep <- read_csv("house_votes_Rep.csv")
```

Goal: Know how to make decisions and answer questions using clustering. 

Repeat the clustering process only using the Rep house votes dataset
- What differences and similarities did you see between how the clustering worked for the datasets?

```{r}
#Select the variables to be included in the cluster 
clust_data_Rep = house_votes_Dem[, c("aye", "nay", "other")]
```

```{r}
#Run the clustering algo with 2 centers
set.seed(1)
kmeans_obj_Rep = kmeans(clust_data_Rep, centers = 2, 
                        algorithm = "Lloyd")
```

```{r}
#View the results
head(kmeans_obj_Rep)
```

```{r}
#Visualize the output
party_clusters_Rep = as.factor(kmeans_obj_Rep$cluster)
ggplot(house_votes_Rep, aes(x = aye, y = nay, color = party.labels, shape = party_clusters_Rep)) + geom_point(size = 6) + ggtitle("Aye vs. Nay votes for Republican-introduced bills") + xlab("Number of Aye Votes") + ylab("Number of Nay Votes") + scale_shape_manual(name="Cluster", labels = c("Cluster 1", "Cluster 2"), values = c("1", "2"))+ scale_color_manual(name = "Party", labels = c("Republican", "Democratic"), values = c("red", "blue")) + theme_light()
```

```{r}
#Evaluate the quality of the clustering 
num_Rep = kmeans_obj_Rep$betweenss
denom_Rep = kmeans_obj_Rep$totss
(var_exp_Rep = num_Rep/denom_Rep)
```

```{r}
#Use the function we created to evaluate several different number of clusters
explained_var = function(data_in, k){
  set.seed(1)
  kmeans_obj = kmeans(data_in, centers = k, algorithm = "Lloyd", iter.max = 30)
  var_exp = kmeans_obj$betweenss / kmeans_obj$totss
}

explained_var_Rep = sapply(1:10, explained_variance, data_in = clust_data_Rep)
elbow_data_Rep = data.frame(k=1:10, explained_var_Rep)
```

```{r}
#Create a elbow chart of the output 
ggplot(elbow_data_Rep, aes(x = k, y = explained_var_Rep))+geom_point(size = 4)+geom_line(size=1)+xlab('k')+ylab('Inter-cluster Variance / Total Variance') + theme_light()

```

```{r}
#Use NbClust to select a number of clusters
library(NbClust)
(nbclust_obj_Rep = NbClust(data = clust_data_Rep, method = "kmeans"))
View(nbclust_obj_Rep$Best.nc)
freq_k_Rep = nbclust_obj_Rep$Best.nc[1,]
freq_k_Rep = data.frame(freq_k_Rep)
max(freq_k_Rep)
```

```{r}
#Display the results visually 
ggplot(freq_k_Rep, aes(x = freq_k_Rep)) + geom_bar() + scale_x_continuous(breaks = seq(0, 15, by = 1)) + scale_y_continuous(breaks = seq(0, 12, by = 1)) + labs(x = "Number of Clusters", y = "Number of Votes", title = "Cluster Analysis")

```

```{r}
#Using the recommended number of cluster compare the quality of the model 
#with 2 clusters 

```
The ideal number of clusters from the Nbclust formula was 2 clusters which was the same as the quality of the model with 2 clusters. From the elbow chart, the steepest rate of change was seen at 2 clusters, which meant that the most predictive model would have 2 clusters. 

```{r}
#Bonus: Create a 3d version of the output
party_color3D_Rep = data.frame(party.labels = c("Democrat", "Republican"), color = c("blue", "red"))
house_votes_color_Rep = inner_join(house_votes_Rep, party_color3D_Rep)
house_votes_color_Rep$clusters <- (party_clusters_Rep)
house_votes_color_Rep$Last.Name <- gsub("[^[:alnum:]]", "", house_votes_color_Rep$Last.Name)
fig <- plot_ly(house_votes_color_Rep, 
               type = "scatter3d", 
               mode = "markers", 
               symbol = ~clusters, 
               x = ~aye, 
               y = ~nay, 
               z = ~other, 
               color = ~color, 
               colors = c('#0C4B8E','#BF382A'), 
               text = ~paste('Representative:',Last.Name,
                             "Party:",party.labels))

fig 
```