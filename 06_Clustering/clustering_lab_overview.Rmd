---
title: "Clustering Lab"
author: "Brian Wright"
date: "9/20/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(plotly)
library(htmltools)
library(devtools)
library(caret)
library(NbClust)
library(readr)
house_votes_Rep <- read_csv("house_votes_Rep.csv")
```

Goal: Know how to make decisions and answer questions using clustering. 

Repeat the clustering process only using the Rep house votes dataset
- What differences and similarities did you see between how the clustering worked for the datasets?

```{r}
#Select the variables to be included in the cluster 
clust_data_Rep = house_votes_Dem[, c("aye", "nay", "other")]
```

```{r}
#Run the clustering algo with 2 centers
set.seed(1)
kmeans_obj_Rep = kmeans(clust_data_Rep, centers = 2, 
                        algorithm = "Lloyd")
```

```{r}
#View the results
head(kmeans_obj_Rep)
```

```{r}
#Visualize the output
party_clusters_Rep = as.factor(kmeans_obj_Rep$cluster)
ggplot(house_votes_Rep, aes(x = aye, y = nay, color = party.labels, shape = party_clusters_Rep)) + geom_point(size = 6) + ggtitle("Aye vs. Nay votes for Republican-introduced bills") + xlab("Number of Aye Votes") + ylab("Number of Nay Votes") + scale_shape_manual(name="Cluster", labels = c("Cluster 1", "Cluster 2"), values = c("1", "2"))+ scale_color_manual(name = "Party", labels = c("Republican", "Democratic"), values = c("red", "blue")) + theme_light()
```

```{r}
#Evaluate the quality of the clustering 
num_Rep = kmeans_obj_Rep$betweenss
denom_Rep = kmeans_obj_Rep$totss
(var_exp_Rep = num_Rep/denom_Rep)
```

```{r}
#Use the function we created to evaluate several different number of clusters
explained_var = function(data_in, k){
  set.seed(1)
  kmeans_obj = kmeans(data_in, centers = k, algorithm = "Lloyd", iter.max = 30)
  var_exp = kmeans_obj$betweenss / kmeans_obj$totss
}

explained_var_Rep = sapply(1:10, explained_variance, data_in = clust_data_Rep)
elbow_data_Rep = data.frame(k=1:10, explained_var_Rep)
```

```{r}
#Create a elbow chart of the output 
ggplot(elbow_data_Rep, aes(x = k, y = explained_var_Rep))+geom_point(size = 4)+geom_line(size=1)+xlab('k')+ylab('Inter-cluster Variance / Total Variance') + theme_light()

```

```{r}
#Use NbClust to select a number of clusters
library(NbClust)
(nbclust_obj_Rep = NbClust(data = clust_data_Rep, method = "kmeans"))
View(nbclust_obj_Rep$Best.nc)
freq_k_Rep = nbclust_obj_Rep$Best.nc[1,]
freq_k_Rep = data.frame(freq_k_Rep)
max(freq_k_Rep)
```

```{r}
#Display the results visually 
ggplot(freq_k_Rep, aes(x = freq_k_Rep)) + geom_bar() + scale_x_continuous(breaks = seq(0, 15, by = 1)) + scale_y_continuous(breaks = seq(0, 12, by = 1)) + labs(x = "Number of Clusters", y = "Number of Votes", title = "Cluster Analysis")

```

```{r}

#Using the recommended number of cluster compare the quality of the model 
#with 2 clusters 
=======
#Using the recommended number of cluster compare the output to the elbow chart method, assuming it's different. 
```

```{r}
# What differences and similarities did you see between how the clustering 
# worked for the datasets? What do these patterns suggest about the           # differences between republican versus  

=======
#Using the recommended number of cluster compare the quality of the model 
#with 2 clusters 
```

```
The ideal number of clusters from the Nbclust formula was 2 clusters which was the same as the quality of the model with 2 clusters. From the elbow chart, the steepest rate of change was seen at 2 clusters, which meant that the most predictive model would have 2 clusters. 

```{r}
#Bonus: Create a 3d version of the output
party_color3D_Rep = data.frame(party.labels = c("Democrat", "Republican"), color = c("blue", "red"))
house_votes_color_Rep = inner_join(house_votes_Rep, party_color3D_Rep)
house_votes_color_Rep$clusters <- (party_clusters_Rep)
house_votes_color_Rep$Last.Name <- gsub("[^[:alnum:]]", "", house_votes_color_Rep$Last.Name)
fig <- plot_ly(house_votes_color_Rep, 
               type = "scatter3d", 
               mode = "markers", 
               symbol = ~clusters, 
               x = ~aye, 
               y = ~nay, 
               z = ~other, 
               color = ~color, 
               colors = c('#0C4B8E','#BF382A'), 
               text = ~paste('Representative:',Last.Name,
                             "Party:",party.labels))

fig 
```
=======
```

In a separate Rmarkdown document work through a similar process 
with the NBA data (nba2020-21 and nba_salaries_21), merge them together. 

You are a scout for the worst team in the NBA, probably the Wizards. Your 
general manager just heard about Data Science and thinks it can solve all the
teams problems!!! She wants you to figure out a way to find players that are 
high performing but maybe not highly paid that you can steal to get the team 
to the playoffs! 

Details: 

- Determine a way to use clustering to estimate based on performance if 
players are under or over paid, generally. 
- Then select three players you believe would be best your team and explain why. 
- Provide a well commented and clean (knitted) report of your findings that can 
be presented to your GM. Include a rationale for variable selection, details 
on your approach and a overview of the results with supporting visualizations. 
- Create a new repo for this assignment either for yourself and 
submit the link along with your knitted report. 

Hints:

- Salary is the variable you are trying to understand 
- You can include numerous performance variables in the clustering but when 
interpreting you might want to use graphs that include variables that are the 
most correlated with Salary
- You'll need to standardize the variables before performing the clustering
- Be specific about why you selected the players that you did, more detail is 
better
- Use good coding practices, comment heavily, indent, don't use for loops unless
totally necessary and create modular sections that align with some outcome. If 
necessary create more than one script,list/load libraries at the top and don't 
include libraries that aren't used. 
  





